<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Introduction to Statistical Inference | Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching introductory data science." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Introduction to Statistical Inference | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching introductory data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Introduction to Statistical Inference | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching introductory data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Trevor Campbell" />
<meta name="author" content="Melissa Lee" />


<meta name="date" content="2020-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> R, Jupyter, and the tidyverse</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.2</b> Jupyter notebooks</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#loading-a-spreadsheet-like-dataset"><i class="fa fa-check"></i><b>1.3</b> Loading a spreadsheet-like dataset</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assigning-value-to-a-data-frame"><i class="fa fa-check"></i><b>1.4</b> Assigning value to a data frame</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#creating-subsets-of-data-frames-with-select-filter"><i class="fa fa-check"></i><b>1.5</b> Creating subsets of data frames with <code>select</code> &amp; <code>filter</code></a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#using-select-to-extract-multiple-columns"><i class="fa fa-check"></i><b>1.5.1</b> Using <code>select</code> to extract multiple columns</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>1.5.2</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#using-filter-to-extract-a-single-row"><i class="fa fa-check"></i><b>1.5.3</b> Using <code>filter</code> to extract a single row</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#using-filter-to-extract-rows-with-values-above-a-threshold"><i class="fa fa-check"></i><b>1.5.4</b> Using <code>filter</code> to extract rows with values above a threshold</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.6</b> Exploring data with visualizations</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot"><i class="fa fa-check"></i><b>1.6.1</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot-1"><i class="fa fa-check"></i><b>1.6.2</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.6.3</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#coloring-points-by-group"><i class="fa fa-check"></i><b>1.6.4</b> Coloring points by group</a></li>
<li class="chapter" data-level="1.6.5" data-path="index.html"><a href="index.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.6.5</b> Putting it all together</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.1</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.2</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.3</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.4</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-data-from-an-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading data from an Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a><ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#reading-data-from-a-sqlite-database"><i class="fa fa-check"></i><b>2.6.1</b> Reading data from a SQLite database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#reading-data-from-a-postgresql-database"><i class="fa fa-check"></i><b>2.6.2</b> Reading data from a PostgreSQL database</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#scraping-data-off-the-web-using-r"><i class="fa fa-check"></i><b>2.8</b> Scraping data off the web using R</a><ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#html-and-css-selectors"><i class="fa fa-check"></i><b>2.8.1</b> HTML and CSS selectors</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#are-you-allowed-to-scrape-that-website"><i class="fa fa-check"></i><b>2.8.2</b> Are you allowed to scrape that website?</a></li>
<li class="chapter" data-level="2.8.3" data-path="reading.html"><a href="reading.html#using-rvest"><i class="fa fa-check"></i><b>2.8.3</b> Using <code>rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#additional-readingsresources"><i class="fa fa-check"></i><b>2.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#vectors-and-data-frames"><i class="fa fa-check"></i><b>3.3</b> Vectors and Data frames</a><ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy Data</a><ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.4.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-gather"><i class="fa fa-check"></i><b>3.4.3</b> Going from wide to long (or tidy!) using <code>gather</code></a></li>
<li class="chapter" data-level="3.4.4" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.4.4</b> Using separate to deal with multiple delimiters</a></li>
<li class="chapter" data-level="3.4.5" data-path="wrangling.html"><a href="wrangling.html#notes-on-defining-tidy-data"><i class="fa fa-check"></i><b>3.4.5</b> Notes on defining tidy data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.5</b> Combining functions using the pipe operator, <code>%&gt;%</code>:</a><ul>
<li class="chapter" data-level="3.5.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.5.1</b> Using <code>%&gt;%</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.5.2</b> Using <code>%&gt;%</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#iterating-over-data-with-group_by-summarize"><i class="fa fa-check"></i><b>3.6</b> Iterating over data with <code>group_by</code> + <code>summarize</code></a><ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>3.6.1</b> Calculating summary statistics:</a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#calculating-group-summary-statistics"><i class="fa fa-check"></i><b>3.6.2</b> Calculating group summary statistics:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#additional-reading-on-the-dplyr-functions"><i class="fa fa-check"></i><b>3.7</b> Additional reading on the <code>dplyr</code> functions</a></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.8</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a><ul>
<li class="chapter" data-level="3.8.1" data-path="wrangling.html"><a href="wrangling.html#a-bit-more-about-the-map_-functions"><i class="fa fa-check"></i><b>3.8.1</b> A bit more about the <code>map_*</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#additional-readingsresources-1"><i class="fa fa-check"></i><b>3.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a><ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a><ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#the-mauna-loa-co2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> The Mauna Loa CO2 data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.2</b> The island landmass data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#the-old-faithful-eruption-waiting-time-data-set"><i class="fa fa-check"></i><b>4.5.3</b> The Old Faithful eruption / waiting time data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#the-michelson-speed-of-light-data-set"><i class="fa fa-check"></i><b>4.5.4</b> The Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="GitHub.html"><a href="GitHub.html"><i class="fa fa-check"></i><b>5</b> Version control with GitHub</a><ul>
<li class="chapter" data-level="5.1" data-path="GitHub.html"><a href="GitHub.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="GitHub.html"><a href="GitHub.html#videos-to-learn-about-version-control-with-github-and-git"><i class="fa fa-check"></i><b>5.2</b> Videos to learn about version control with GitHub and Git</a><ul>
<li class="chapter" data-level="5.2.1" data-path="GitHub.html"><a href="GitHub.html#creating-a-github-repository"><i class="fa fa-check"></i><b>5.2.1</b> Creating a GitHub repository</a></li>
<li class="chapter" data-level="5.2.2" data-path="GitHub.html"><a href="GitHub.html#exploring-a-github-repository"><i class="fa fa-check"></i><b>5.2.2</b> Exploring a GitHub repository</a></li>
<li class="chapter" data-level="5.2.3" data-path="GitHub.html"><a href="GitHub.html#directly-editing-files-on-github"><i class="fa fa-check"></i><b>5.2.3</b> Directly editing files on GitHub</a></li>
<li class="chapter" data-level="5.2.4" data-path="GitHub.html"><a href="GitHub.html#logging-changes-and-pushing-them-to-github"><i class="fa fa-check"></i><b>5.2.4</b> Logging changes and pushing them to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="GitHub.html"><a href="GitHub.html#git-command-cheatsheet"><i class="fa fa-check"></i><b>5.3</b> Git command cheatsheet</a><ul>
<li class="chapter" data-level="5.3.1" data-path="GitHub.html"><a href="GitHub.html#getting-a-repository-from-github-onto-the-server-for-the-first-time"><i class="fa fa-check"></i><b>5.3.1</b> Getting a repository from GitHub onto the server for the first time</a></li>
<li class="chapter" data-level="5.3.2" data-path="GitHub.html"><a href="GitHub.html#logging-changes"><i class="fa fa-check"></i><b>5.3.2</b> Logging changes</a></li>
<li class="chapter" data-level="5.3.3" data-path="GitHub.html"><a href="GitHub.html#sending-your-changes-back-to-github"><i class="fa fa-check"></i><b>5.3.3</b> Sending your changes back to GitHub</a></li>
<li class="chapter" data-level="5.3.4" data-path="GitHub.html"><a href="GitHub.html#getting-changes"><i class="fa fa-check"></i><b>5.3.4</b> Getting changes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="GitHub.html"><a href="GitHub.html#terminal-cheatsheet"><i class="fa fa-check"></i><b>5.4</b> Terminal cheatsheet</a><ul>
<li class="chapter" data-level="5.4.1" data-path="GitHub.html"><a href="GitHub.html#see-where-you-are"><i class="fa fa-check"></i><b>5.4.1</b> See where you are:</a></li>
<li class="chapter" data-level="5.4.2" data-path="GitHub.html"><a href="GitHub.html#see-what-is-inside-the-directory-where-you-are"><i class="fa fa-check"></i><b>5.4.2</b> See what is inside the directory where you are:</a></li>
<li class="chapter" data-level="5.4.3" data-path="GitHub.html"><a href="GitHub.html#move-to-a-different-directory"><i class="fa fa-check"></i><b>5.4.3</b> Move to a different directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification I: training &amp; predicting</a><ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-4"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#the-classification-problem"><i class="fa fa-check"></i><b>6.3</b> The classification problem</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#exploring-a-labelled-data-set"><i class="fa fa-check"></i><b>6.4</b> Exploring a labelled data set</a></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#classification-with-k-nearest-neighbours"><i class="fa fa-check"></i><b>6.5</b> Classification with K-nearest neighbours</a></li>
<li class="chapter" data-level="6.6" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-with-tidymodels"><i class="fa fa-check"></i><b>6.6</b> K-nearest neighbours with <code>tidymodels</code></a></li>
<li class="chapter" data-level="6.7" data-path="classification.html"><a href="classification.html#data-preprocessing-with-tidymodels"><i class="fa fa-check"></i><b>6.7</b> Data preprocessing with <code>tidymodels</code></a><ul>
<li class="chapter" data-level="6.7.1" data-path="classification.html"><a href="classification.html#centering-and-scaling"><i class="fa fa-check"></i><b>6.7.1</b> Centering and scaling</a></li>
<li class="chapter" data-level="6.7.2" data-path="classification.html"><a href="classification.html#balancing"><i class="fa fa-check"></i><b>6.7.2</b> Balancing</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="classification.html"><a href="classification.html#putting-it-together-in-a-workflow"><i class="fa fa-check"></i><b>6.8</b> Putting it together in a <code>workflow</code></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification II: evaluation &amp; tuning</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-5"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#evaluating-accuracy"><i class="fa fa-check"></i><b>7.3</b> Evaluating accuracy</a></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#tuning-the-classifier"><i class="fa fa-check"></i><b>7.4</b> Tuning the classifier</a><ul>
<li class="chapter" data-level="7.4.1" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation"><i class="fa fa-check"></i><b>7.4.1</b> Cross-validation</a></li>
<li class="chapter" data-level="7.4.2" data-path="classification-continued.html"><a href="classification-continued.html#parameter-value-selection"><i class="fa fa-check"></i><b>7.4.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="7.4.3" data-path="classification-continued.html"><a href="classification-continued.html#underoverfitting"><i class="fa fa-check"></i><b>7.4.3</b> Under/overfitting</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#splitting-data"><i class="fa fa-check"></i><b>7.5</b> Splitting data</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#summary"><i class="fa fa-check"></i><b>7.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Regression I: K-nearest neighbours</a><ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#regression"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#sacremento-real-estate-example"><i class="fa fa-check"></i><b>8.4</b> Sacremento real estate example</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#training-evaluating-and-tuning-the-model"><i class="fa fa-check"></i><b>8.6</b> Training, evaluating, and tuning the model</a></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>8.7</b> Underfitting and overfitting</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#evaluating-on-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Evaluating on the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of K-NN regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression1.html"><a href="regression1.html#multivariate-k-nn-regression"><i class="fa fa-check"></i><b>8.10</b> Multivariate K-NN regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression II: linear regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r"><i class="fa fa-check"></i><b>9.4</b> Linear regression in R</a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>9.5</b> Comparing simple linear and K-NN regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#the-other-side-of-regression"><i class="fa fa-check"></i><b>9.7</b> The other side of regression</a></li>
<li class="chapter" data-level="9.8" data-path="regression2.html"><a href="regression2.html#additional-readingsresources-2"><i class="fa fa-check"></i><b>9.8</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>10</b> Clustering</a><ul>
<li class="chapter" data-level="10.1" data-path="clustering.html"><a href="clustering.html#overview-8"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>10.3</b> Clustering</a></li>
<li class="chapter" data-level="10.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>10.4</b> K-means</a><ul>
<li class="chapter" data-level="10.4.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>10.4.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="10.4.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>10.4.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="10.4.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>10.4.3</b> Random restarts</a></li>
<li class="chapter" data-level="10.4.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>10.4.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>10.5</b> K-means in R</a></li>
<li class="chapter" data-level="10.6" data-path="clustering.html"><a href="clustering.html#additional-readings"><i class="fa fa-check"></i><b>10.6</b> Additional readings:</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>11</b> Introduction to Statistical Inference</a><ul>
<li class="chapter" data-level="11.1" data-path="inference.html"><a href="inference.html#overview-9"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="inference.html"><a href="inference.html#chapter-learning-objectives-9"><i class="fa fa-check"></i><b>11.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="inference.html"><a href="inference.html#why-do-we-need-sampling"><i class="fa fa-check"></i><b>11.3</b> Why do we need sampling?</a></li>
<li class="chapter" data-level="11.4" data-path="inference.html"><a href="inference.html#sampling-distributions"><i class="fa fa-check"></i><b>11.4</b> Sampling distributions</a><ul>
<li class="chapter" data-level="11.4.1" data-path="inference.html"><a href="inference.html#sampling-distributions-for-proportions"><i class="fa fa-check"></i><b>11.4.1</b> Sampling distributions for proportions</a></li>
<li class="chapter" data-level="11.4.2" data-path="inference.html"><a href="inference.html#sampling-distributions-for-means"><i class="fa fa-check"></i><b>11.4.2</b> Sampling distributions for means</a></li>
<li class="chapter" data-level="11.4.3" data-path="inference.html"><a href="inference.html#summary-1"><i class="fa fa-check"></i><b>11.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="inference.html"><a href="inference.html#bootstrapping"><i class="fa fa-check"></i><b>11.5</b> Bootstrapping</a><ul>
<li class="chapter" data-level="11.5.1" data-path="inference.html"><a href="inference.html#overview-10"><i class="fa fa-check"></i><b>11.5.1</b> Overview</a></li>
<li class="chapter" data-level="11.5.2" data-path="inference.html"><a href="inference.html#bootstrapping-in-r"><i class="fa fa-check"></i><b>11.5.2</b> Bootstrapping in R</a></li>
<li class="chapter" data-level="11.5.3" data-path="inference.html"><a href="inference.html#using-the-bootstrap-to-calculate-a-plausible-range"><i class="fa fa-check"></i><b>11.5.3</b> Using the bootstrap to calculate a plausible range</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="inference.html"><a href="inference.html#additional-readings-1"><i class="fa fa-check"></i><b>11.6</b> Additional readings</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Introduction to Statistical Inference</h1>
<div id="overview-9" class="section level2">
<h2><span class="header-section-number">11.1</span> Overview</h2>
<p>In almost all data analysis tasks in practice, we want to draw conclusions about some unknown
aspect of a population of interest based on observed data sampled from that
population; we typically do not get data on the <em>full</em> population.
Data analysis questions regarding how summaries,
patterns, trends, or relationships in a dataset
extend to the wider population are called <em>inferential questions</em>. This chapter will start
with the fundamental ideas of sampling from populations, and then will work towards
introducing two common techniques in statistical inference: <em>point estimation</em> and
<em>interval estimation</em>.</p>
</div>
<div id="chapter-learning-objectives-9" class="section level2">
<h2><span class="header-section-number">11.2</span> Chapter learning objectives</h2>
<p>By the end of the chapter, students will be able to:</p>
<ul>
<li>Describe real-world examples of questions that can be answered with the statistical inference.</li>
<li>Define common population parameters (e.g. mean, proportion, standard deviation) that are often estimated using sampled data, and estimate these from a sample.</li>
<li>Define the following statistical sampling terms (population, sample, population parameter, point estimate, sampling distribution).</li>
<li>Explain the difference between a population parameter and sample point estimate.</li>
<li>Use R to draw random samples from a finite population.</li>
<li>Use R to create a sampling distribution from a finite population.</li>
<li>Describe how sample size influences the sampling distribution.</li>
<li>Define bootstrapping.</li>
<li>Use R to create a bootstrap distribution to approximate a sampling distribution.</li>
<li>Contrast the bootstrap and sampling distributions.</li>
</ul>
</div>
<div id="why-do-we-need-sampling" class="section level2">
<h2><span class="header-section-number">11.3</span> Why do we need sampling?</h2>
<p>Statistical inference can help us decide how quantities we observe in
a subset of data relate to the same quantities in the broader
population. Here is an example question that we might use statistical inference to answer:</p>
<p><em>What proportion of all undergraduate students in North America own an iPhone?</em></p>
<p>In the above question, we are interested in making a conclusion about <em>all</em>
undergraduate students in North America. This is our <strong>population</strong>:
in general, the population is the complete collection of individuals or cases we are interested in studying.
Further, in the above question, we are interested in computing a quantity—the proportion
of iPhone owners—based on the entire population. This is our <strong>population parameter</strong>:
in general, a population parameter is a numerical characteristic
of the entire population. In order to compute this number in the example above, we would need to ask
every single undergraduate in North America whether or not they own an iPhone. In practice,
directly computing population parameters is often time-consuming and costly, and sometimes impossible.</p>
<p>A more practical approach would be to collect measurements for a <strong>sample</strong>: a subset of
individuals collected from the population. We can then compute a <strong>sample statistic</strong>—a numerical
characteristic of the sample—that estimates the population parameter. For example, if we
randomly selected 100 undergraduate students across North America (the sample) and computed the fraction of those
students who own an iPhone (the sample statistic), we might suspect that that fraction is a reasonable
estimate of the full population fraction.</p>
<center>
<img src="img/population_vs_sample.svg" title="fig:" alt="Figure 11.1: Population versus sample" />
</center>
<p>Note that proportions are not the <em>only</em> kind of population parameter we might be interested in.
Let’s consider another example question that we might tackle with statistical inference:</p>
<p><em>What is the average price-per-night of one-bedroom apartment rentals in Vancouver, Canada?</em></p>
<p>Here, the population consists of all one-bedroom apartment rental offerings in Vancouver, and the population
parameter is the <em>average price-per-night</em>. But even within this one example, we could also be interested
in many other population parameters: the median price, the fraction of
one-bedroom apartments that cost more than $200 per night,
the standard deviation of the price, and the list goes on.
If we were somehow able to observe the whole population of one-bedroom apartments in Vancouver,
we could compute each of these numbers exactly; therefore these are all population parameters.
There are many kinds of observations and population parameters that you will run into in practice,
but in this chapter we will focus on two settings:</p>
<ol style="list-style-type: decimal">
<li>Using categorical observations to estimate the proportion of each category</li>
<li>Using quantitative observations to estimate the average (or mean)</li>
</ol>
</div>
<div id="sampling-distributions" class="section level2">
<h2><span class="header-section-number">11.4</span> Sampling distributions</h2>
<div id="sampling-distributions-for-proportions" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Sampling distributions for proportions</h3>
<p>Let’s start with an illustrative (and tasty!) example. Timbits are
bite-sized doughnuts sold at Tim Hortons, a popular Canadian-based fast-food restaurant
chain founded in Hamilton, Ontario, Canada.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Timbits2.jpg/1600px-Timbits2.jpg" style="width:50.0%" alt="" />
<p class="caption">Timbits. Source: wikimedia.org</p>
</div>
<p>Suppose we wanted to estimate the true proportion of chocolate doughnuts at Tim
Hortons restaurants. Now, of course, we (the authors!) do not have access to the true population.
So in this chapter, we will simulate a synthetic box of 10,000 Timbits with two types—old-fashioned
and chocolate—as our population, and use this to illustrate
inferential concepts. Below we create a <code>tibble()</code> with a subject ID and Timbit type as our columns.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="inference.html#cb291-1"></a><span class="kw">library</span>(tidyverse) </span>
<span id="cb291-2"><a href="inference.html#cb291-2"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb291-3"><a href="inference.html#cb291-3"></a><span class="kw">library</span>(infer)</span>
<span id="cb291-4"><a href="inference.html#cb291-4"></a><span class="kw">library</span>(gridExtra)</span>
<span id="cb291-5"><a href="inference.html#cb291-5"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb291-6"><a href="inference.html#cb291-6"></a>virtual_box &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">timbit_id =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10000</span>, <span class="dt">by =</span> <span class="dv">1</span>),</span>
<span id="cb291-7"><a href="inference.html#cb291-7"></a>                     <span class="dt">color =</span> <span class="kw">factor</span>(<span class="kw">rbinom</span>(<span class="dv">10000</span>, <span class="dv">1</span>, <span class="fl">0.63</span>),</span>
<span id="cb291-8"><a href="inference.html#cb291-8"></a>                     <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;old fashioned&quot;</span>, <span class="st">&quot;chocolate&quot;</span>)))</span>
<span id="cb291-9"><a href="inference.html#cb291-9"></a><span class="kw">head</span>(virtual_box)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   timbit_id color        
##       &lt;dbl&gt; &lt;fct&gt;        
## 1         1 chocolate    
## 2         2 chocolate    
## 3         3 chocolate    
## 4         4 chocolate    
## 5         5 old fashioned
## 6         6 old fashioned</code></pre>
<p>From our simulated box, we can see that the proportion of chocolate Timbits is
0.63. This value, 0.63, is the <em>population parameter</em>. Note that this parameter value is
usually unknown in real data analysis problems.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="inference.html#cb293-1"></a>virtual_box <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb293-2"><a href="inference.html#cb293-2"></a><span class="st">    </span><span class="kw">group_by</span>(color) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb293-3"><a href="inference.html#cb293-3"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(),</span>
<span id="cb293-4"><a href="inference.html#cb293-4"></a>             <span class="dt">proportion =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span><span class="dv">10000</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   color             n proportion
##   &lt;fct&gt;         &lt;int&gt;      &lt;dbl&gt;
## 1 old fashioned  3705      0.370
## 2 chocolate      6295      0.630</code></pre>
<p>Suppose we buy a box of 40 randomly-selected Timbits and count the number of chocolate Timbits,
i.e., take a random sample of size 40 from our Timbits population. The function
<code>rep_sample_n</code> from the <code>infer</code> package will allow us to sample. The arguments
of <code>rep_sample_n</code> are (1) the data frame to sample from, and (2) the size of the sample
to take.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="inference.html#cb295-1"></a>samples_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rep_sample_n</span>(<span class="dt">tbl =</span> virtual_box, <span class="dt">size =</span> <span class="dv">40</span>)</span>
<span id="cb295-2"><a href="inference.html#cb295-2"></a>choc_sample_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">summarize</span>(samples_<span class="dv">1</span>, <span class="dt">n =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;chocolate&quot;</span>),</span>
<span id="cb295-3"><a href="inference.html#cb295-3"></a>                                        <span class="dt">prop =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;chocolate&quot;</span>) <span class="op">/</span><span class="st"> </span><span class="dv">40</span>)</span>
<span id="cb295-4"><a href="inference.html#cb295-4"></a>choc_sample_<span class="dv">1</span></span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate     n  prop
##       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1         1    20   0.5</code></pre>
<p>Here we see that the proportion of chocolate Timbits in this random sample is
0.5. This value is our sample statistic; since it is a single
value that is used to estimate a population parameter, we refer to it as a <strong>point estimate</strong>.</p>
<p>Now imagine we took another random sample of 40 Timbits from the population. Do you
think you would get the same proportion? Let’s try sampling from the population
again and see what happens.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="inference.html#cb297-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb297-2"><a href="inference.html#cb297-2"></a>samples_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">rep_sample_n</span>(virtual_box, <span class="dt">size =</span> <span class="dv">40</span>)</span>
<span id="cb297-3"><a href="inference.html#cb297-3"></a>choc_sample_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">summarize</span>(samples_<span class="dv">2</span>, <span class="dt">n =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;chocolate&quot;</span>),</span>
<span id="cb297-4"><a href="inference.html#cb297-4"></a>                                        <span class="dt">prop =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;chocolate&quot;</span>) <span class="op">/</span><span class="st"> </span><span class="dv">40</span>)</span>
<span id="cb297-5"><a href="inference.html#cb297-5"></a>choc_sample_<span class="dv">2</span></span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate     n  prop
##       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1         1    27 0.675</code></pre>
<p>Notice that we get a different value for our statistic this time. The
proportion of chocolate Timbits in this sample is 0.68.
If we were to do this again, another random sample could also give a
different result. Statistics vary from sample to sample
due to <strong>sampling variability</strong>.</p>
<p>But just how much should we expect the statistics of our random
samples to vary? In order to understand this, we will simulate more samples
of size 40 from our population of Timbits, and calculate the
proportion of chocolate Timbits in each sample. We can then
construct the distribution of sample proportions we calculate. The distribution
of the statistic for all possible samples of size <span class="math inline">\(n\)</span> from a population is
called a <strong>sampling distribution</strong>. The sampling distribution will help us see
how much we would expect our sample proportions from this population to vary
for samples of size 40. Below we again use the <code>rep_sample_n</code> to take samples
of size 40 from our population of Timbits, but we set the <code>reps</code> argument
to specify the number of samples to take.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="inference.html#cb299-1"></a>samples &lt;-<span class="st"> </span><span class="kw">rep_sample_n</span>(virtual_box, <span class="dt">size =</span> <span class="dv">40</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb299-2"><a href="inference.html#cb299-2"></a><span class="kw">head</span>(samples)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 3
## # Groups:   replicate [1]
##   replicate timbit_id color        
##       &lt;int&gt;     &lt;dbl&gt; &lt;fct&gt;        
## 1         1      9054 chocolate    
## 2         1      4322 old fashioned
## 3         1      1685 chocolate    
## 4         1      3958 chocolate    
## 5         1      2765 old fashioned
## 6         1       358 old fashioned</code></pre>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="inference.html#cb301-1"></a><span class="kw">tail</span>(samples)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 3
## # Groups:   replicate [1]
##   replicate timbit_id color        
##       &lt;int&gt;     &lt;dbl&gt; &lt;fct&gt;        
## 1      1000      4677 chocolate    
## 2      1000      3619 chocolate    
## 3      1000       142 old fashioned
## 4      1000      8991 chocolate    
## 5      1000      8945 chocolate    
## 6      1000      7564 old fashioned</code></pre>
<p>Notice the column <code>replicate</code> is indicating the replicate with which each
Timbit belongs. Since we took 1000 samples of size 40, there are 1000 replicates.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="inference.html#cb303-1"></a>sample_estimates &lt;-<span class="st"> </span>samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb303-2"><a href="inference.html#cb303-2"></a><span class="st">    </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb303-3"><a href="inference.html#cb303-3"></a><span class="st">    </span><span class="kw">summarise</span>(<span class="dt">sample_proportion =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;chocolate&quot;</span>) <span class="op">/</span><span class="st"> </span><span class="dv">40</span>)</span>
<span id="cb303-4"><a href="inference.html#cb303-4"></a><span class="kw">head</span>(sample_estimates)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   replicate sample_proportion
##       &lt;int&gt;             &lt;dbl&gt;
## 1         1             0.625
## 2         2             0.675
## 3         3             0.7  
## 4         4             0.675
## 5         5             0.45 
## 6         6             0.425</code></pre>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="inference.html#cb305-1"></a><span class="kw">tail</span>(sample_estimates)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   replicate sample_proportion
##       &lt;int&gt;             &lt;dbl&gt;
## 1       995             0.675
## 2       996             0.75 
## 3       997             0.7  
## 4       998             0.475
## 5       999             0.6  
## 6      1000             0.375</code></pre>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="inference.html#cb307-1"></a>sampling_distribution &lt;-<span class="st">  </span><span class="kw">ggplot</span>(sample_estimates, <span class="kw">aes</span>(<span class="dt">x =</span> sample_proportion)) <span class="op">+</span></span>
<span id="cb307-2"><a href="inference.html#cb307-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.05</span>) <span class="op">+</span></span>
<span id="cb307-3"><a href="inference.html#cb307-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Sample proportions&quot;</span>) </span>
<span id="cb307-4"><a href="inference.html#cb307-4"></a>sampling_distribution</span></code></pre></div>
<div class="figure"><span id="fig:10-example-proportions7"></span>
<img src="_main_files/figure-html/10-example-proportions7-1.png" alt="Sampling distribution of the sample proportion for sample size 40" width="672" />
<p class="caption">
Figure 11.1: Sampling distribution of the sample proportion for sample size 40
</p>
</div>
<p>The sampling distribution appears to be bell-shaped with one peak. It is
centered around 0.6 and the
sample proportions range from about 0.3 to
about 0.8. In fact, we can calculate
the mean and standard deviation of the sample proportions.</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="inference.html#cb308-1"></a>sample_estimates <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb308-2"><a href="inference.html#cb308-2"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(sample_proportion), <span class="dt">sd =</span> <span class="kw">sd</span>(sample_proportion))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##    mean     sd
##   &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.621 0.0783</code></pre>
<p>We notice that the sample proportions are centred around the population
proportion value. The standard deviation of the sample proportions
is 0.078.</p>
<blockquote>
<p><strong>Note:</strong> If random samples of size <span class="math inline">\(n\)</span> are taken from a population, <span class="math inline">\(\hat{p}\)</span> will be approximately Normal with mean <span class="math inline">\(p\)</span> and standard deviation <span class="math inline">\(\sqrt{\frac{p(1-p)}{n}}\)</span> as long as the sample size <span class="math inline">\(n\)</span> is large enough such that <span class="math inline">\(np\)</span> and <span class="math inline">\(n(1 - p)\)</span> are at least 10, where <span class="math inline">\(p\)</span> is the population proportion, <span class="math inline">\(\hat{p}\)</span> is the sample proportion and <span class="math inline">\(n\)</span> is the sample size.</p>
</blockquote>
</div>
<div id="sampling-distributions-for-means" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Sampling distributions for means</h3>
<p>In the previous section, our variable of interest—Timbit flavour—was
<em>categorical</em>, and the population parameter of interest was the proportion of chocolate
Timbits. What if we wanted to infer something about a population of <em>quantitative</em> variables instead?
As mentioned in the introduction to this chapter, there are many choices of population parameter
for each type of observed variable. In this section, we will study the case where we are interested
in the population mean of a quantitative variable.</p>
<p>In particular, we will look at an example using data from Airbnb, an online
marketplace for arranging or offering places to stay. The dataset contains
Airbnb listings for Vancouver, Canada, in September 2020
from <a href="http://insideairbnb.com/">Inside Airbnb</a>.
Let’s imagine (for learning purposes) that our dataset represents the population of all Airbnb rental listings in Vancouver,
and we are interested in the population mean price per night.
Our data contains an ID number, neighbourhood,
type of room, the number of people that the rental accommodates, number of
bathrooms, bedrooms, beds, and the price per night.</p>
<pre><code>## # A tibble: 6 x 8
##      id neighbourhood     room_type  accommodates bathrooms bedrooms  beds price
##   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     1 Downtown          Entire ho…            5 2 baths          2     2   150
## 2     2 Downtown Eastside Entire ho…            4 2 baths          2     2   132
## 3     3 West End          Entire ho…            2 1 bath           1     1    85
## 4     4 Kensington-Cedar… Entire ho…            2 1 bath           1     0   146
## 5     5 Kensington-Cedar… Entire ho…            4 1 bath           1     2   110
## 6     6 Hastings-Sunrise  Entire ho…            4 1 bath           2     3   195</code></pre>
<p>We can visualize the population distribution of the price per night with a histogram.</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="inference.html#cb311-1"></a>population_distribution &lt;-<span class="st">  </span><span class="kw">ggplot</span>(airbnb, <span class="kw">aes</span>(<span class="dt">x =</span> price)) <span class="op">+</span></span>
<span id="cb311-2"><a href="inference.html#cb311-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span></span>
<span id="cb311-3"><a href="inference.html#cb311-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Price per night ($)&quot;</span>) </span>
<span id="cb311-4"><a href="inference.html#cb311-4"></a>population_distribution</span></code></pre></div>
<div class="figure"><span id="fig:10-example-means2"></span>
<img src="_main_files/figure-html/10-example-means2-1.png" alt="Population distribution of price per night ($) for all Airbnb listings in Vancouver, Canada" width="672" />
<p class="caption">
Figure 11.2: Population distribution of price per night ($) for all Airbnb listings in Vancouver, Canada
</p>
</div>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="inference.html#cb312-1"></a>population_parameters &lt;-<span class="st"> </span>airbnb <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb312-2"><a href="inference.html#cb312-2"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">pop_mean =</span> <span class="kw">mean</span>(price),</span>
<span id="cb312-3"><a href="inference.html#cb312-3"></a>             <span class="dt">pop_sd =</span> <span class="kw">sd</span>(price))</span>
<span id="cb312-4"><a href="inference.html#cb312-4"></a>population_parameters</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   pop_mean pop_sd
##      &lt;dbl&gt;  &lt;dbl&gt;
## 1     155.   116.</code></pre>
<p>We see that the distribution has one peak and is skewed—most of the listings
are less than $250 per night, but a small proportion of listings cost more
than that, creating a long tail on the histogram’s right side.
The population mean is $154.51 and the
population standard deviation is $115.79.</p>
<p>Suppose we take a sample of 20 observations from our population. Below we
create a histogram to visualize the
distribution of observations in the sample,
and calculate the mean and standard deviation of our sample. These two numbers
are <strong>point estimates</strong> for the mean and standard deviation of the full population.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="inference.html#cb314-1"></a>sample_<span class="dv">1</span> &lt;-<span class="st"> </span>airbnb <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb314-2"><a href="inference.html#cb314-2"></a><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dv">20</span>)</span>
<span id="cb314-3"><a href="inference.html#cb314-3"></a><span class="kw">head</span>(sample_<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 9
## # Groups:   replicate [1]
##   replicate    id neighbourhood room_type accommodates bathrooms bedrooms  beds
##       &lt;int&gt; &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;
## 1         1   401 Kitsilano     Private …            2 2 baths          2     2
## 2         1  3187 South Cambie  Private …            4 1 privat…        1     2
## 3         1  2127 Sunset        Entire h…            8 2 baths          3     4
## 4         1  3203 Downtown      Entire h…            4 1 bath           1     0
## 5         1   455 Kitsilano     Entire h…            6 2 baths          3     3
## 6         1  3116 Marpole       Entire h…            2 1 bath           1     1
## # … with 1 more variable: price &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="inference.html#cb316-1"></a>sample_distribution &lt;-<span class="st"> </span><span class="kw">ggplot</span>(sample_<span class="dv">1</span>, <span class="kw">aes</span>(price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb316-2"><a href="inference.html#cb316-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span></span>
<span id="cb316-3"><a href="inference.html#cb316-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Price per night ($)&quot;</span>) </span>
<span id="cb316-4"><a href="inference.html#cb316-4"></a>sample_distribution</span></code></pre></div>
<div class="figure"><span id="fig:10-example-means3"></span>
<img src="_main_files/figure-html/10-example-means3-1.png" alt="Distribution of price per night ($) for sample of 20 Airbnb listings" width="672" />
<p class="caption">
Figure 11.3: Distribution of price per night ($) for sample of 20 Airbnb listings
</p>
</div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="inference.html#cb317-1"></a>estimates &lt;-<span class="st"> </span>sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb317-2"><a href="inference.html#cb317-2"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">sample_mean =</span> <span class="kw">mean</span>(price),</span>
<span id="cb317-3"><a href="inference.html#cb317-3"></a>             <span class="dt">sample_sd =</span> <span class="kw">sd</span>(price))</span>
<span id="cb317-4"><a href="inference.html#cb317-4"></a>estimates</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate sample_mean sample_sd
##       &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;
## 1         1        168.      117.</code></pre>
<p>Recall that the population mean
was $154.51 and the population standard deviation
was $115.79. We see that our point
estimates for the mean and standard deviation
are $167.93 and $116.96,
respectively. So our estimates were actually quite close to the population parameters: the mean was
about 8.7% off,
while the standard deviation was
about 1% off.
Note that in practice, we usually cannot compute the accuracy of the estimate, since we do not have access to the population
parameter; if we did, we wouldn’t need to estimate it!</p>
<p>Also recall from the previous section that the point estimate can vary; if
we took another random sample from the population, then the value of our statistic may change.
So then did we just get lucky with our point estimate above?
How much does our estimate vary across different samples of size 20 in this example? Again, since we have access to the population,
we can take many samples and plot the <strong>sampling distribution</strong> of the point estimates to get a sense
for this variation. In this case, we’ll use 1500 samples of size 20.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="inference.html#cb319-1"></a>samples &lt;-<span class="st"> </span><span class="kw">rep_sample_n</span>(airbnb, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">reps =</span> <span class="dv">1500</span>)</span>
<span id="cb319-2"><a href="inference.html#cb319-2"></a><span class="kw">head</span>(samples)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 9
## # Groups:   replicate [1]
##   replicate    id neighbourhood room_type accommodates bathrooms bedrooms  beds
##       &lt;int&gt; &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;
## 1         1  3750 Hastings-Sun… Entire h…            4 1 bath           2     2
## 2         1  3254 Hastings-Sun… Entire h…            2 1 bath           1     1
## 3         1  2318 Mount Pleasa… Entire h…            4 1.5 baths        2     2
## 4         1  3940 West Point G… Private …            1 1 shared…        1     1
## 5         1  4331 West End      Entire h…            4 1 bath           1     1
## 6         1   159 Mount Pleasa… Entire h…            5 2.5 baths        3     3
## # … with 1 more variable: price &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="inference.html#cb321-1"></a>sample_estimates &lt;-<span class="st"> </span>samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb321-2"><a href="inference.html#cb321-2"></a><span class="st">    </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb321-3"><a href="inference.html#cb321-3"></a><span class="st">    </span><span class="kw">summarise</span>(<span class="dt">sample_mean =</span> <span class="kw">mean</span>(price))</span>
<span id="cb321-4"><a href="inference.html#cb321-4"></a><span class="kw">head</span>(sample_estimates)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   replicate sample_mean
##       &lt;int&gt;       &lt;dbl&gt;
## 1         1        164.
## 2         2        201.
## 3         3        185 
## 4         4        190.
## 5         5        156.
## 6         6        158.</code></pre>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="inference.html#cb323-1"></a>sampling_distribution_<span class="dv">20</span> &lt;-<span class="st">  </span><span class="kw">ggplot</span>(sample_estimates, <span class="kw">aes</span>(<span class="dt">x =</span> sample_mean)) <span class="op">+</span></span>
<span id="cb323-2"><a href="inference.html#cb323-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb323-3"><a href="inference.html#cb323-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Sample mean price per night ($)&quot;</span>) </span>
<span id="cb323-4"><a href="inference.html#cb323-4"></a>sampling_distribution_<span class="dv">20</span></span></code></pre></div>
<div class="figure"><span id="fig:10-example-means4"></span>
<img src="_main_files/figure-html/10-example-means4-1.png" alt="Sampling distribution of the sample means for sample size of 20" width="672" />
<p class="caption">
Figure 11.4: Sampling distribution of the sample means for sample size of 20
</p>
</div>
<p>Here we see that the sampling distribution of the mean has one peak and is
bell-shaped. Most of the estimates are between
about $140 and
$170; but there are
a good fraction of cases outside this range (i.e., where the point estimate
was not close to the population parameter). So it does indeed look like we were quite lucky
when we estimated the population mean
with only 8.7% error.
Let’s visualize the population
distribution, distribution of the sample, and the sampling distribution on one
plot to compare them.
<!---

```r
sample_estimates %>% 
  summarise(mean_of_sample_means = mean(sample_mean))
```

```
## # A tibble: 1 x 1
##   mean_of_sample_means
##                  <dbl>
## 1                 155.
```
Notice that the mean of the sample means is \$155.08. Recall that the population mean
was \$154.51. 
--></p>
<div class="figure"><span id="fig:10-example-means5"></span>
<img src="_main_files/figure-html/10-example-means5-1.png" alt="Comparision of population distribution, sample distribution and sampling distribution" width="672" />
<p class="caption">
Figure 11.5: Comparision of population distribution, sample distribution and sampling distribution
</p>
</div>
<p>Given that there is quite a bit of variation in the sampling distribution of the sample mean—i.e.,
the point estimate that we obtain is not very reliable—is there any way to improve the estimate?
One way to improve a point estimate is to take a <em>larger</em> sample. To illustrate what effect this has,
we will take 1500 samples of size 20, 50, 100, and 500, and plot the sampling distribution of the sample mean
below.</p>
<div class="figure"><span id="fig:10-example-means7"></span>
<img src="_main_files/figure-html/10-example-means7-1.png" alt="Comparision of sampling distributions" width="672" />
<p class="caption">
Figure 11.6: Comparision of sampling distributions
</p>
</div>
<p>Based on the visualization, two points about the sample mean become clear.
First, the
mean of the sample mean (across samples) is equal to the population mean.
Second, increasing the size of the sample
decreases the standard deviation (i.e., the variability) in the sample mean
point estimate of the population mean. Therefore, a larger sample size results
in a more reliable point estimate of the population parameter.</p>
<blockquote>
<p><strong>Note:</strong> If random samples of size <span class="math inline">\(n\)</span> are taken from a population, the sample mean <span class="math inline">\(\bar{x}\)</span> will be approximately Normal with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> as long as the sample size <span class="math inline">\(n\)</span> is large enough. <span class="math inline">\(\mu\)</span> is the population mean, <span class="math inline">\(\sigma\)</span> is the population standard deviation, <span class="math inline">\(\bar{x}\)</span> is the sample mean, and <span class="math inline">\(n\)</span> is the sample size.
If samples are selected from a finite population as we are doing in this chapter, we should apply a finite population correction. We multiply <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> by <span class="math inline">\(\sqrt{\frac{N - n}{N - 1}}\)</span> where <span class="math inline">\(N\)</span> is the population size and <span class="math inline">\(n\)</span> is the sample size. If our sample size, <span class="math inline">\(n\)</span>, is small relative to the population size, this finite correction factor is less important.</p>
</blockquote>
</div>
<div id="summary-1" class="section level3">
<h3><span class="header-section-number">11.4.3</span> Summary</h3>
<ol style="list-style-type: decimal">
<li>A <em>statistic</em> is a value computed using a sample from a population; a <em>point estimate</em> is a statistic that is a single value (e.g. a mean or proportion)</li>
<li>The <em>sampling distribution</em> of a statistic is the distribution of the statistic for all possible samples of a fixed size from the same population.</li>
<li>The sample means and proportions calculated from samples are centered around the population mean and proportion, respectively.</li>
<li>The spread of the sampling distribution is related to the sample size. As the sample size increases, the spread of the sampling distribution decreases.</li>
<li>The shape of the sampling distribution is usually bell-shaped with one peak and centred at the population mean or proportion.</li>
</ol>
</div>
</div>
<div id="bootstrapping" class="section level2">
<h2><span class="header-section-number">11.5</span> Bootstrapping</h2>
<div id="overview-10" class="section level3">
<h3><span class="header-section-number">11.5.1</span> Overview</h3>
<p>We saw in the previous section that we could compute a <strong>point estimate</strong> of a population
parameter using a sample of observations from the population. And since we had access to the
population, we could evaluate how accurate the estimate was, and even get a sense for how much
the estimate would vary for different samples from the population.
But in real data analysis settings, we usually have <em>just one sample</em> from our population,
and do not have access to the population itself. So how do we get a sense for how
variable our point estimate is when we only have one sample to work with?
In this section, we will discuss <strong>interval estimation</strong> and construct <strong>confidence intervals</strong>
using just a single sample from a population.</p>
<p>Here is the key idea. First, if you take a big enough sample, it <em>looks like</em> the population.</p>
<p><strong>[TODO: visualize increasing sample size means sample looks like pop]</strong></p>
<p>In the previous section, we took many samples of the same size <em>from our population</em> to get
a sense for the variability of a sample statistic. But if our sample is big enough that it looks like our population,
we can pretend that our sample <em>is</em> the population, and take more samples (with replacement) of the same size
from it instead! This very clever technique is called <strong>the bootstrap</strong>.
Note that by taking many samples from our single, observed sample, we do not obtain the true sampling distribution,
but rather an approximation that we call <strong>the bootstrap distribution</strong>.</p>
<blockquote>
<p>Note that we need to sample <em>with</em> replacement when using the bootstrap. Otherwise, if we had a sample of size <span class="math inline">\(n\)</span>,
and obtained a sample from it of size <span class="math inline">\(n\)</span> <em>without</em> replacement, it would just return our original sample.</p>
</blockquote>
<p>This section will explore how to create a bootstrap distribution from a single sample using R.
For a sample of size <span class="math inline">\(n\)</span>, the process we will go through is as follows:</p>
<ol style="list-style-type: decimal">
<li>Randomly select an observation from the original sample, which was drawn from the population</li>
<li>Record the observation’s value</li>
<li>Replace that observation</li>
<li>Repeat steps 1 - 3 (sampling <em>with</em> replacement) until you have <span class="math inline">\(n\)</span> observations, which form a bootstrap sample</li>
<li>Calculate the bootstrap point estimate (e.g., mean, median, proportion, slope, etc.) of the <span class="math inline">\(n\)</span> observations in your bootstrap sample</li>
<li>Repeat steps (1) - (5) many times to create a distribution of point estimates (the bootstrap distribution)</li>
<li>Calculate the plausible range of values around our observed point estimate</li>
</ol>
</div>
<div id="bootstrapping-in-r" class="section level3">
<h3><span class="header-section-number">11.5.2</span> Bootstrapping in R</h3>
<p>Let’s continue working with our Airbnb data. Once again, let’s say we are interested
in estimating the population mean price per night of all Airbnb listings in
Vancouver, Canada. We will draw a single sample of size 40 from the
population and visualize the distribution of the sample:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="inference.html#cb324-1"></a>one_sample &lt;-<span class="st"> </span>airbnb <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb324-2"><a href="inference.html#cb324-2"></a><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dv">40</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb324-3"><a href="inference.html#cb324-3"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># ungroup the data frame </span></span>
<span id="cb324-4"><a href="inference.html#cb324-4"></a><span class="st">    </span><span class="kw">select</span>(price) <span class="co"># drop the replicate column </span></span>
<span id="cb324-5"><a href="inference.html#cb324-5"></a><span class="kw">head</span>(one_sample)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 1
##   price
##   &lt;dbl&gt;
## 1   300
## 2   168
## 3   140
## 4   199
## 5    60
## 6   450</code></pre>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="inference.html#cb326-1"></a>one_sample_dist &lt;-<span class="st"> </span><span class="kw">ggplot</span>(one_sample, <span class="kw">aes</span>(price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb326-2"><a href="inference.html#cb326-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span></span>
<span id="cb326-3"><a href="inference.html#cb326-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Price per night ($)&quot;</span>) </span>
<span id="cb326-4"><a href="inference.html#cb326-4"></a>one_sample_dist</span></code></pre></div>
<div class="figure"><span id="fig:10-bootstrapping1"></span>
<img src="_main_files/figure-html/10-bootstrapping1-1.png" alt="Histogram of price per night ($) for one sample of size 20" width="672" />
<p class="caption">
Figure 11.7: Histogram of price per night ($) for one sample of size 20
</p>
</div>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="inference.html#cb327-1"></a>one_sample_estimates &lt;-<span class="st"> </span>one_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb327-2"><a href="inference.html#cb327-2"></a><span class="st">    </span><span class="kw">summarise</span>(<span class="dt">sample_mean =</span> <span class="kw">mean</span>(price))</span>
<span id="cb327-3"><a href="inference.html#cb327-3"></a>one_sample_estimates</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   sample_mean
##         &lt;dbl&gt;
## 1        162.</code></pre>
<p>The sample distribution is skewed with a few observations out to the right. The
mean of the sample is $161.5.
Remember, in practice, we usually only have one sample from the population. So
this sample and estimate are the only data we can work with.</p>
<p>We now perform steps 1 - 5 listed above to generate a single bootstrap sample in R using the
sample we just took, and calculate the bootstrap estimate for that sample. We
will use the <code>rep_sample_n</code> function as we did when we were creating our
sampling distribution. Since we want to sample with replacement, we change the
argument for <code>replace</code> from its default value of <code>FALSE</code> to <code>TRUE</code>.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="inference.html#cb329-1"></a>boot1 &lt;-<span class="st"> </span>one_sample <span class="op">%&gt;%</span></span>
<span id="cb329-2"><a href="inference.html#cb329-2"></a><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">40</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1</span>)</span>
<span id="cb329-3"><a href="inference.html#cb329-3"></a><span class="kw">head</span>(boot1)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
## # Groups:   replicate [1]
##   replicate price
##       &lt;int&gt; &lt;dbl&gt;
## 1         1   150
## 2         1   188
## 3         1   380
## 4         1   168
## 5         1   150
## 6         1    85</code></pre>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="inference.html#cb331-1"></a>boot1_dist &lt;-<span class="st"> </span><span class="kw">ggplot</span>(boot1, <span class="kw">aes</span>(price)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb331-2"><a href="inference.html#cb331-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span></span>
<span id="cb331-3"><a href="inference.html#cb331-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Price per night ($)&quot;</span>) <span class="op">+</span></span>
<span id="cb331-4"><a href="inference.html#cb331-4"></a><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;Bootstrap distribution&quot;</span>)</span>
<span id="cb331-5"><a href="inference.html#cb331-5"></a></span>
<span id="cb331-6"><a href="inference.html#cb331-6"></a>boot1_dist</span></code></pre></div>
<p><img src="_main_files/figure-html/10-bootstrapping3-1.png" width="672" /></p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="inference.html#cb332-1"></a><span class="kw">summarise</span>(boot1, <span class="dt">mean =</span> <span class="kw">mean</span>(price))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   replicate  mean
##       &lt;int&gt; &lt;dbl&gt;
## 1         1   151</code></pre>
<p>Notice that our bootstrap distribution has a similar shape to the original
sample distribution. Though the shapes of the distributions are similar, they
are not identical. You’ll also notice that the original sample mean and the
bootstrap sample mean differ. How might that happen? Remember that we are
sampling with replacement from the original sample, so we don’t end up with the
same sample values again. We are trying to mimic drawing another sample from
the population without actually having to do that.</p>
<p>Let’s now take 1500 bootstrap samples from the original sample we drew from the
population (<code>one_sample</code>) using <code>rep_sample_n</code> and calculate the means for
each of those replicates. Recall that this assumes that <code>one_sample</code> <em>looks like</em>
our original population; but since we do not have access to the population itself,
this is often the best we can do.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="inference.html#cb334-1"></a>boot1500 &lt;-<span class="st"> </span>one_sample <span class="op">%&gt;%</span></span>
<span id="cb334-2"><a href="inference.html#cb334-2"></a><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">40</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1500</span>)</span>
<span id="cb334-3"><a href="inference.html#cb334-3"></a><span class="kw">head</span>(boot1500)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
## # Groups:   replicate [1]
##   replicate price
##       &lt;int&gt; &lt;dbl&gt;
## 1         1   125
## 2         1   188
## 3         1   112
## 4         1    95
## 5         1   140
## 6         1    79</code></pre>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="inference.html#cb336-1"></a><span class="kw">tail</span>(boot1500)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
## # Groups:   replicate [1]
##   replicate price
##       &lt;int&gt; &lt;dbl&gt;
## 1      1500   150
## 2      1500    60
## 3      1500   100
## 4      1500   112
## 5      1500   111
## 6      1500    99</code></pre>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="inference.html#cb338-1"></a>boot1500_means &lt;-<span class="st"> </span>boot1500 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb338-2"><a href="inference.html#cb338-2"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb338-3"><a href="inference.html#cb338-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(price))</span>
<span id="cb338-4"><a href="inference.html#cb338-4"></a><span class="kw">head</span>(boot1500_means)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   replicate  mean
##       &lt;int&gt; &lt;dbl&gt;
## 1         1  146.
## 2         2  144.
## 3         3  155.
## 4         4  158.
## 5         5  149.
## 6         6  174.</code></pre>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="inference.html#cb340-1"></a><span class="kw">tail</span>(boot1500_means)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   replicate  mean
##       &lt;int&gt; &lt;dbl&gt;
## 1      1495  171.
## 2      1496  161.
## 3      1497  162 
## 4      1498  164.
## 5      1499  139.
## 6      1500  161.</code></pre>
<p>We now calculate point estimates for each bootstrap sample and generate a bootstrap
distribution of our point estimates. The bootstrap distribution suggests how we
might expect our point estimate to behave if we took another sample.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="inference.html#cb342-1"></a>boot_est_dist &lt;-<span class="st">  </span><span class="kw">ggplot</span>(boot1500_means, <span class="kw">aes</span>(<span class="dt">x =</span> mean)) <span class="op">+</span></span>
<span id="cb342-2"><a href="inference.html#cb342-2"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill=</span><span class="st">&quot;#0072B2&quot;</span>, <span class="dt">color=</span><span class="st">&quot;#e9ecef&quot;</span>) <span class="op">+</span></span>
<span id="cb342-3"><a href="inference.html#cb342-3"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Sample mean price per night ($)&quot;</span>) </span></code></pre></div>
<p>Let’s compare our bootstrap distribution with the true sampling distribution (taking many samples from the population).</p>
<div class="figure"><span id="fig:10-bootstrapping6"></span>
<img src="_main_files/figure-html/10-bootstrapping6-1.png" alt="Comparison of distribution of the bootstrap sample means and sampling distribution" width="672" />
<p class="caption">
Figure 11.8: Comparison of distribution of the bootstrap sample means and sampling distribution
</p>
</div>
<p>There are two important points that we can take away from these plots.
First, we see how the sampling distribution is centred at $154.51, the
population mean value, as we learned in
the previous section. However, the bootstrap distribution is centred at $161.56, which
is the original sample’s mean price per night. This is because we are resampling from the original sample over and
over again, so we see that the bootstrap distribution is centred at the
original sample’s mean value. The second important point is that the shape and spread of the true sampling distribution
and the bootstrap distribution is similar; the bootstrap distribution lets us get a sense for the variability of the
point estimate.</p>
<div class="figure"><span id="fig:10-bootstrapping7"></span>
<img src="_main_files/figure-html/10-bootstrapping7-1.png" alt="Summary of bootstrapping process" width="672" />
<p class="caption">
Figure 11.9: Summary of bootstrapping process
</p>
</div>
</div>
<div id="using-the-bootstrap-to-calculate-a-plausible-range" class="section level3">
<h3><span class="header-section-number">11.5.3</span> Using the bootstrap to calculate a plausible range</h3>
<p>Now that we have constructed our bootstrap distribution let’s use it to create
a <em>confidence interval</em> for the mean, a range of plausible values for the
population mean. Confidence intervals can be set at different levels. Common
levels are 90%, 95% and 99%. There is a balance between your level of
confidence and an interval’s precision, so the confidence level you choose will
depend on the application. Suppose we want to construct a 95% confidence
interval using the bootstrap distribution we found earlier.</p>
<p>To calculate a 95% confidence interval using bootstrapping:</p>
<ol style="list-style-type: decimal">
<li>Arrange the observations in the bootstrap distribution in ascending order</li>
<li>Find the value such that 2.5% of observations fall below it (the 2.5% percentile). Use that value as the lower bound of the interval</li>
<li>Find the value such that 97.5% of observations fall below it (the 97.5% percentile). Use that value as the upper bound of the interval</li>
</ol>
<p>To do this in R, we can use the <code>quantile()</code> function:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="inference.html#cb343-1"></a>bounds &lt;-<span class="st"> </span>boot1500_means <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb343-2"><a href="inference.html#cb343-2"></a><span class="st">    </span><span class="kw">select</span>(mean) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb343-3"><a href="inference.html#cb343-3"></a><span class="st">    </span><span class="kw">pull</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb343-4"><a href="inference.html#cb343-4"></a><span class="st">    </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb343-5"><a href="inference.html#cb343-5"></a>bounds</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 136.3356 189.6656</code></pre>
<p>We’re 95% “confident” that the true population mean price per night of Airbnb
listings in Vancouver is between $136.34 and $189.67. Suppose
we repeated this process of sampling and constructing confidence intervals more times with more samples. We’d expect
95% of intervals would contain the true population parameter.</p>
<div class="figure"><span id="fig:10-bootstrapping9"></span>
<img src="_main_files/figure-html/10-bootstrapping9-1.png" alt="Distribution of the bootstrap sample means with 95% confidence interval lower and upper bounds" width="672" />
<p class="caption">
Figure 11.10: Distribution of the bootstrap sample means with 95% confidence interval lower and upper bounds
</p>
</div>
<p>Here we notice that our 95% confidence interval does indeed contain the true
population mean value, $154.51! However, in
practice, we would not know whether our interval captured the true population
parameter or not because we usually only have a single sample, not the entire
population.</p>
</div>
</div>
<div id="additional-readings-1" class="section level2">
<h2><span class="header-section-number">11.6</span> Additional readings</h2>
<p>For more about statistical inference and bootstrapping, refer to pages 187-190<br />
of <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">Introduction to Statistical Learning with Applications in R</a> by
Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani, and Chapters 7 - 8 of <a href="https://moderndive.com/">Modern Dive</a> Statistical
Inference via Data Science by Chester Ismay and Albert Y. Kim.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clustering.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-inference.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
