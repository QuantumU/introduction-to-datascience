# Introduction to Statistical Inference {#inference}

```{r set-up, echo = F, message = F}
library(tidyverse) 
require(grid) #  grid.bezier()

max_count <- function(dist) {
  max(ggplot_build(dist)$data[[1]]$count)
}

max_x <- function(dist){ 
  max(ggplot_build(dist)$data[[1]]$xmax)
}

min_x <- function(dist) {
  ggp_data <- ggplot_build(dist)
  min(ggp_data$data[[1]]$xmin)
}
```


## Overview
In almost all data analysis tasks in practice, we want to draw conclusions about some unknown
aspect of a population of interest based on observed data sampled from that
population; we typically do not get data on the *full* population.
Data analysis questions regarding how summaries, 
patterns, trends, or relationships in a dataset 
extend to the wider population are called *inferential questions*. This chapter will start
with the fundamental ideas of sampling from populations, and then will work towards
introducing two common techniques in statistical inference: *point estimation* and
*interval estimation*. 

## Chapter learning objectives 
By the end of the chapter, students will be able to:

* Describe real-world examples of questions that can be answered with the statistical inference.
* Define common population parameters (e.g. mean, proportion, standard deviation) that are often estimated using sampled data, and estimate these from a sample.
* Define the following statistical sampling terms (population, sample, population parameter, point estimate, sampling distribution).
* Explain the difference between a population parameter and sample point estimate.
* Use R to draw random samples from a finite population.
* Use R to create a sampling distribution from a finite population.
* Describe how sample size influences the sampling distribution.
* Define bootstrapping.
* Use R to create a bootstrap distribution to approximate a sampling distribution.
* Contrast the bootstrap and sampling distributions.

## Why do we need sampling? 
Statistical inference can help us decide how quantities we observe in
a subset of data relate to the same quantities in the broader
population. Here is an example question that we might use statistical inference to answer:

*What proportion of all undergraduate students in North America own an iPhone?*

In the above question, we are interested in making a conclusion about *all*
undergraduate students in North America.  This is our **population**: 
in general, the population is the complete collection of individuals or cases we are interested in studying. 
Further, in the above question, we are interested in computing a quantity&mdash;the proportion
of iPhone owners&mdash;based on the entire population. This is our **population parameter**:
in general, a population parameter is a numerical characteristic
of the entire population. In order to compute this number in the example above, we would need to ask 
every single undergraduate in North America whether or not they own an iPhone. In practice,
directly computing population parameters is often time-consuming and costly, and sometimes impossible. 

A more practical approach would be to collect measurements for a **sample**: a subset of
individuals collected from the population. We can then compute a **sample statistic**&mdash;a numerical
characteristic of the sample&mdash;that estimates the population parameter. For example, if we 
randomly selected 100 undergraduate students across North America (the sample) and computed the fraction of those
students who own an iPhone (the sample statistic), we might suspect that that fraction is a reasonable
estimate of the full population fraction. 

<center>
![Figure 11.1: Population versus sample](img/population_vs_sample.svg){}
</center>

Note that proportions are not the *only* kind of population parameter we might be interested in.
Let's consider another example question that we might tackle with statistical inference:

*What is the average price of one-bedroom apartments in Vancouver, Canada?*

Here, the population consists of all one-bedroom apartments in Vancouver, and the population
parameter is the *average price*. But even within this one example, we could also be interested
in many other population parameters: the median price, the fraction of one-bedroom apartments that cost more than 1 million dollars,
the standard deviation of the price, and the list goes on.
If we were somehow able to observe the whole population of one-bedroom apartments in Vancouver, 
we could compute each of these numbers exactly; therefore these are all population parameters. 
There are many kinds of observations and population parameters that you will run into in practice,
but in this chapter we will focus on two settings:

1. Using quantitative observations to estimate the average (or mean)
2. Using categorical observations to estimate the proportion of each category

## Sampling distributions

### Sampling distributions for proportions

Let's start with an illustrative (and tasty!) example. Timbits are 
bite-sized doughnuts sold at Tim Hortons, a popular Canadian-based fast-food restaurant
chain founded in Hamilton, Ontario, Canada. 

![Timbits. Source: wikimedia.org](https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Timbits2.jpg/1600px-Timbits2.jpg){width=50%}

Suppose we wanted to estimate the true proportion of chocolate doughnuts at Tim
Hortons restaurants. Now, of course, we (the authors!) do not have access to the true population.
So in this chapter, we will simulate a synthetic box of 10,000 Timbits with two types&mdash;old-fashioned 
and chocolate&mdash;as our population, and use this to illustrate
inferential concepts. Below we create a `tibble()` with a subject ID and Timbit type as our columns.

```{r 10-example-proportions, echo = TRUE, message = FALSE, warning = FALSE}
library(tidyverse) 
library(ggplot2)
library(infer)
library(gridExtra)
set.seed(1234)
virtual_box <- tibble(timbit_id = seq(1, 10000, by = 1),
                     color = factor(rbinom(10000, 1, 0.63),
                     labels = c("old fashioned", "chocolate")))
head(virtual_box)
```

From our simulated box, we can see that the proportion of chocolate Timbits is
0.63. This value, 0.63, is the *population parameter*. Note that this parameter value is
usually unknown in real data analysis problems.

```{r 10-example-proportions2, echo = TRUE, message = FALSE, warning = FALSE}
virtual_box %>% 
    group_by(color) %>% 
    summarize(n = n(),
             proportion = n() / 10000)
```

Suppose we buy a box of 40 randomly-selected Timbits and count the number of chocolate Timbits,
i.e., take a random sample of size 40 from our Timbits population. The function
`rep_sample_n` from the `infer` package will allow us to sample. The arguments
of `rep_sample_n` are (1) the data frame to sample from, and (2) the size of the sample
to take.

```{r 10-example-proportions3, echo = TRUE, message = FALSE, warning = FALSE}
samples_1 <- rep_sample_n(tbl = virtual_box, size = 40)
choc_sample_1 <- summarize(samples_1, n = sum(color == "chocolate"),
                                        prop = sum(color == "chocolate") / 40)
choc_sample_1
```
Here we see that the proportion of chocolate Timbits in this random sample is
`r round(choc_sample_1$prop,2)`. This value is our sample statistic; since it is a single
value that is used to estimate a population parameter, we refer to it as a **point estimate**.

Now imagine we took another random sample of 40 Timbits from the population. Do you
think you would get the same proportion? Let's try sampling from the population
again and see what happens. 

```{r 10-example-proportions4, echo = TRUE, message = FALSE, warning = FALSE}
set.seed(2)
samples_2 <- rep_sample_n(virtual_box, size = 40)
choc_sample_2 <- summarize(samples_2, n = sum(color == "chocolate"),
                                        prop = sum(color == "chocolate") / 40)
choc_sample_2
```

Notice that we get a different value for our statistic this time. The
proportion of chocolate Timbits in this sample is `r round(choc_sample_2$prop, 2)`. 
If we were to do this again, another random sample could also give a
different result. Statistics vary from sample to sample 
due to **sampling variability**. 

But just how much should we expect the statistics of our random
samples to vary? In order to understand this, we will simulate more samples
of size 40 from our population of Timbits, and calculate the 
proportion of chocolate Timbits in each sample. We can then
construct the distribution of sample proportions we calculate. The distribution
of the statistic for all possible samples of size $n$ from a population is
called a **sampling distribution**. The sampling distribution will help us see
how much we would expect our sample proportions from this population to vary
for samples of size 40. Below we again use the `rep_sample_n` to take samples
of size 40 from our population of Timbits, but we set the `reps` argument
to specify the number of samples to take.

```{r 10-example-proportions5, echo = TRUE, message = FALSE, warning = FALSE}
samples <- rep_sample_n(virtual_box, size = 40, reps = 1000)
head(samples)
tail(samples)
```

Notice the column `replicate` is indicating the replicate with which each
Timbit belongs. Since we took 1000 samples of size 40, there are 1000 replicates.

```{r 10-example-proportions6, echo = TRUE, message = FALSE, warning = FALSE}
sample_estimates <- samples %>% 
    group_by(replicate) %>% 
    summarise(sample_proportion = sum(color == "chocolate") / 40)
head(sample_estimates)
tail(sample_estimates)
```

```{r 10-example-proportions7, echo = TRUE, message = FALSE, warning = FALSE,fig.cap = "Sampling distribution of the sample proportion for sample size 40"}
sampling_distribution <-  ggplot(sample_estimates, aes(x = sample_proportion)) +
    geom_histogram(fill="#0072B2", color="#e9ecef", binwidth = 0.05) +
    xlab("Sample proportions") 
sampling_distribution
```

The sampling distribution appears to be bell-shaped with one peak. It is
centered around `r round(mean(sample_estimates$sample_proportion),1)` and the
sample proportions range from about `r round(min(sample_estimates$sample_proportion), 1)` to 
about `r round(max(sample_estimates$sample_proportion), 1)`. In fact, we can calculate
the mean and standard deviation of the sample proportions. 

```{r 10-example-proportions8, echo = TRUE, message = FALSE, warning = FALSE}
sample_estimates %>% 
  summarise(mean = mean(sample_proportion), sd = sd(sample_proportion))
```

We notice that the sample proportions are centred around the population
proportion value. The standard deviation of the sample proportions 
is `r round(sd(sample_estimates$sample_proportion), 3)`.

<!--
> **Note:** If random samples of size $n$ are taken from a population, $\hat{p}$ will be approximately Normal with mean $p$ and standard deviation $\sqrt{\frac{p(1-p)}{n}}$ as long as the sample size $n$ is large enough such that $np$ and $n(1 - p)$ are at least 10, where $p$ is the population proportion, $\hat{p}$ is the sample proportion and $n$ is the sample size. 
-->


### Sampling distributions for means 

In the previous section, our variable of interest, Timbit type, was
categorical. Thus the population parameter that we inferred was the population
proportion. What if we want to infer something about a quantitative variable?
If the variable of interest is quantitative, the population parameter that we
infer about is the population mean. 

Here we will look at an example with Airbnb data. Airbnb is an online
marketplace for arranging or offering places to stay. The dataset contains
Airbnb listings for Vancouver, Canada, in September 2020 
from [Inside Airbnb](http://insideairbnb.com/).  Suppose we were interested in estimating
the average price per night of all Airbnb rentals in Vancouver, Canada. Let's
imagine that we have the population data for all Airbnb listings in Vancouver.
We rarely have measurements for our entire population. However, for this
example, we will pretend that we do so that we can learn about sampling and
estimation for sample means. Our data contains an id number, neighbourhood,
type of room, the number of people that the rental accommodates, number of
bathrooms, bedrooms, beds, and finally, the listing price per night.

```{r 10-example-means1, echo = FALSE, message = FALSE, warning = FALSE}
airbnb <- read_csv("data/listings.csv") %>% 
  select(id, neighbourhood = neighbourhood_cleansed, room_type, accommodates, bathrooms = bathrooms_text, bedrooms, beds,  price) %>% 
  mutate(price = as.numeric(str_remove(price, "[$]"))) %>% 
  na.omit()
airbnb <- airbnb %>% 
  mutate(id = 1:nrow(airbnb))
head(airbnb)
```

We can visualize the population distribution with a histogram. 
```{r 10-example-means2, echo = TRUE, message = FALSE, warning = FALSE, fig.cap = "Population distribution of price per night ($) for all Airbnb listings in Vancouver, Canada"}
population_distribution <-  ggplot(airbnb, aes(x = price)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Price per night ($)") 
population_distribution
population_parameters <- airbnb %>% 
    summarize(pop_mean = mean(price),
             pop_sd = sd(price))
population_parameters

mean(airbnb$price)
```
We see that the distribution has one peak and is skewed -- most of the listings are less than \$250 per night. Still, a small proportion of listings cost more than that, creating a long tail on the histogram's right side. Here we can see the population mean is \$`r round(population_parameters$pop_mean,2)` and the population standard deviation is \$`r round(population_parameters$pop_sd, 2)`.

We can take a sample of 20 observations and create a histogram to visualize the distribution and calculate point estimates for the mean and standard deviation.

```{r 10-example-means3, echo = TRUE, message = FALSE, warning = FALSE, fig.cap = "Distribution of price per night ($) for sample of 20 Airbnb listings"}
sample_1 <- airbnb %>% 
    rep_sample_n(20)
head(sample_1)
sample_distribution <- ggplot(sample_1, aes(price)) + 
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Price per night ($)") 
sample_distribution
estimates <- sample_1 %>% 
    summarize(sample_mean = mean(price),
             sample_sd = sd(price))
estimates
```

Remember that the population mean was \$`r round(population_parameters$pop_mean,2)` and the population standard deviation was \$`r round(population_parameters$pop_sd,2)`. We see that our point estimates for the mean and standard deviation are \$`r round(estimates$sample_mean, 2)` and  \$`r round(estimates$sample_sd,2)` respectively. So how good was our estimate? In practice, we don't usually have access to population data. If we took another random sample from the population, then the value of our statistic may change. So we might want to consider how far an estimate of the parameter could be away from the true population parameter? We might also want to know how often that might occur? Therefore, it will help if we investigate all possible values that a statistic could take. 

```{r 10-example-means4, echo = TRUE, message = FALSE, warning = FALSE, fig.cap= "Sampling distribution of the sample means for sample size of 20"}
samples <- rep_sample_n(airbnb, size = 20, reps = 1500)
head(samples)

sample_estimates <- samples %>% 
    group_by(replicate) %>% 
    summarise(sample_mean = mean(price))
head(sample_estimates)

sampling_distribution_20 <-  ggplot(sample_estimates, aes(x = sample_mean)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") + 
    xlab("Sample mean price per night ($)") 
sampling_distribution_20
```

Here we see that the sampling distribution of the mean has one peak and is bell-shaped. Most of the estimates are between about  \$`r round(quantile(sample_estimates$sample_mean)[2], -1)` and \$`r round(quantile(sample_estimates$sample_mean)[4], -1)`.

```{r 10-example-means4.5}
sample_estimates %>% 
  summarise(mean_of_sample_means = mean(sample_mean))
```
Notice that the mean of the sample means is `r round(mean(sample_estimates$sample_mean),2)`. Recall that the population mean was \$`r round(mean(airbnb$price),2)`. We can compare the population distribution, distribution of the sample, and the sampling distribution on one graph. 

```{r 10-example-means5, echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Comparision of population distribution, sample distribution and sampling distribution"}
grid.arrange(population_distribution + ggtitle("Distribution of population"), 
             sample_distribution + ggtitle("Distribution of sample"), 
             sampling_distribution_20 + ggtitle("Sampling distribution of sample mean"), nrow = 3)
```

Can we do better than that? What if we increase the sample size? Again we will take a random sample of a specific size from the population, calculate the sample mean, and repeat. You can compare the population distribution and the sampling distributions for samples of size 20, 50 and 100 below. 

```{r 10-example-means6, echo = FALSE, message = FALSE, warning = FALSE}
## Sampling n = 50 and n = 100 
sample_estimates_50 <- rep_sample_n(airbnb, size = 50, reps = 1500) %>% 
    group_by(replicate) %>% 
    summarise(sample_mean = mean(price))

sample_estimates_100 <- rep_sample_n(airbnb, size = 100, reps = 1500) %>% 
    group_by(replicate) %>% 
    summarise(sample_mean = mean(price))

## Sampling distribution n = 50 
sampling_distribution_50 <-  ggplot(sample_estimates_50, aes(x = sample_mean)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Sample mean price per night($)") +
    ggtitle("n = 50") + xlim(min_x(sampling_distribution_20), max_x(sampling_distribution_20))

## Sampling distribution n = 100 
sampling_distribution_100 <-  ggplot(sample_estimates_100, aes(x = sample_mean)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Sample mean price per night ($)") +
    ggtitle("n = 100") + xlim(min_x(sampling_distribution_20), max_x(sampling_distribution_20))
```

```{r 10-example-means7,  echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Comparision of population distribution and sampling distributions"}
annotated_population <- population_distribution + 
    geom_vline(xintercept = round(population_parameters$pop_mean,1), col = "red") +
    ggtitle("Population distribution")  + 
    annotate("text", x = max_x(population_distribution), y= max_count(population_distribution), hjust = 1, vjust = 1, 
             label = paste("mean = ", round(population_parameters$pop_mean,1))) +
    annotate("text", x =  max_x(population_distribution), y = max_count(population_distribution), hjust = 1, vjust = 3,
             label = paste("sd = ", round(population_parameters$pop_sd,1)))

annotated_sampling_dist_20 <- sampling_distribution_20 + 
    geom_vline(xintercept = mean(sample_estimates$sample_mean), col = "red") +
    xlim(min_x(sampling_distribution_20), max_x(sampling_distribution_20)) + 
    ggtitle("n = 20") + 
    annotate("text", x = max_x(sampling_distribution_20), y= max_count(sampling_distribution_20), hjust = 1, vjust = 1,
             label = paste("mean = ", round(mean(sample_estimates$sample_mean), 1)))+
    annotate("text", x =  max_x(sampling_distribution_20), y = max_count(sampling_distribution_20), hjust = 1, vjust = 3,
               label = paste("sd = ", round(sd(sample_estimates$sample_mean), 1)))

annotated_sampling_dist_50 <- sampling_distribution_50 + 
    geom_vline(xintercept = mean(sample_estimates_50$sample_mean), col = "red") +
    ## x limits set the same as n = 20 graph, y is this graph 
    annotate("text", x = max_x(sampling_distribution_20), y= max_count(sampling_distribution_50), hjust = 1, vjust = 1,
             label = paste("mean = ", round(mean(sample_estimates_50$sample_mean), 1))) +
    annotate("text", x =  max_x(sampling_distribution_20), y = max_count(sampling_distribution_50), hjust = 1, vjust = 3,
                 label = paste("sd = ", round(sd(sample_estimates_50$sample_mean), 1)))

annotated_sampling_dist_100 <- sampling_distribution_100 + 
    geom_vline(xintercept = mean(sample_estimates_100$sample_mean), col = "red") +
    annotate("text", x =  max_x(sampling_distribution_20), y = max_count(sampling_distribution_100), hjust = 1, vjust = 1,
             label = paste("mean = ", round(mean(sample_estimates_100$sample_mean), 1)))+
    annotate("text", x =  max_x(sampling_distribution_20), y = max_count(sampling_distribution_100), hjust = 1, vjust = 3,
               label = paste("sd = ", round(sd(sample_estimates_100$sample_mean), 1)))

grid.arrange(annotated_population, 
             annotated_sampling_dist_20, 
             annotated_sampling_dist_50, 
             annotated_sampling_dist_100,  
             nrow = 2, ncol = 2) 
```

What do we notice? The center of the sample mean values are equal to the population mean as indicated by the red vertical line. Also, when the sample size increases, the sample mean shows less variability. Therefore, we get more precise estimates of the population parameter.

> **Note:** If random samples of size $n$ are taken from a population, the sample mean $\bar{x}$ will be approximately Normal with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$ as long as the sample size $n$ is large enough. $\mu$ is the population mean, $\sigma$ is the population standard deviation, $\bar{x}$ is the sample mean, and $n$ is the sample size. 
> If samples are selected from a finite population as we are doing in this chapter, we should apply a finite population correction. We multiply $\frac{\sigma}{\sqrt{n}}$ by $\sqrt{\frac{N - n}{N - 1}}$ where $N$ is the population size and $n$ is the sample size. If our sample size, $n$, is small relative to the population size, this finite correction factor is less important. 

### Summary
1. A sampling distribution of a statistic is the distribution of the statistic for all possible samples from the same population of a given sample size.
2. The sample means and proportions calculated from samples drawn from populations were centered around the population parameters we were trying to estimate.
3.	The spread of the sampling distribution is related to the sample size. As the sample size increases, the spread of the distribution decreases. 
4. The shape of the sampling distribution is bell-shaped with one peak and centred at the population mean or proportion.

## Bootstrapping 
### Bootstrapping Overview 

We saw that our sample mean and sample proportions centred around the population parameter we were trying to estimate.	When we estimate the unknown parameter of interest using a single value, we are doing **point estimation**, a form of statistical inference. However, we saw above that many of the estimates we take won't be the exact value of the population quantity we are trying to estimate. So what can we do? Perhaps we can give some plausible range of values for the true population parameter rather than just reporting a single value. The next section will discuss **interval estimation** and construct **confidence intervals**. 

We can construct confidence intervals using information from a sampling distribution. However, we would need certain conditions and assumptions about the population distribution to do so. We can also use ** bootstrapping**, which can be used to construct a bootstrap distribution and confidence interval given specific sample data. Bootstrapping is a procedure where we use data from a single sample from the population to generate a distribution by repeatedly sampling with replacement from our original sample data. This section will explore how to create a bootstrap distribution from a single sample using R.

For a sample of size $n$, the process we will go through is as follows: 

1. Randomly select an observation from the original sample, which was drawn from the population
2. Record the observation's value 
3. Replace that observation
4. Repeat steps 1 - 3 (sampling with replacement) until you have $n$ observations, which form a bootstrap sample
5. Calculate the bootstrap point estimate (e.g., mean, median, proportion, slope, etc.) of the $n$ observations in your bootstrap sample
6. Repeat steps (1) - (5) many times to create a distribution of point estimates (bootstrap distribution)
7. Calculate the plausible range of values around our observed point estimate

### Bootstrapping in R 
Let's continue working with our Airbnb data. Again let's say we are interested in estimating the population mean price per night of all Airbnb listings in Vancouver, Canada. Let's draw a single sample of size `r 40` from the population and visualize the distribution of the sample:

```{r 10-bootstrapping1, echo = TRUE, message = FALSE, warning = FALSE, fig.cap = "Histogram of price per night ($) for one sample of size 20"}
one_sample <- airbnb %>% 
    rep_sample_n(40) %>% 
    ungroup() %>% # ungroup the data frame 
    select(price) # drop the replicate column 
head(one_sample)
one_sample_dist <- ggplot(one_sample, aes(price)) + 
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Price per night ($)") 
one_sample_dist
```

```{r 10-bootstrapping2, echo = TRUE, message = FALSE, warning = FALSE}
one_sample_estimates <- one_sample %>% 
    summarise(sample_mean = mean(price))
one_sample_estimates
```

The sample distribution is skewed with a few observations out to the right. The mean of the sample is \$`r round(one_sample_estimates$sample_mean,2)`. Remember, in practice, we usually only have one sample from the population. So this sample and estimate are what we have to work with.

We do steps 1 - 5 above to generate a single bootstrap sample in R using the sample we just took and calculate the bootstrap estimate for that sample. We will use the `rep_sample_n` function as we did when we were creating our sampling distribution. Since we want to sample with replacement, we change the argument for `replace` from its default value of `FALSE` to `TRUE`.


```{r 10-bootstrapping3, echo = TRUE, message = FALSE, warning = FALSE}
boot1 <- one_sample %>%
    rep_sample_n(size = 40, replace = TRUE, reps = 1)
head(boot1)
boot1_dist <- ggplot(boot1, aes(price)) + 
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Price per night ($)") +
    ggtitle("Bootstrap distribution")

boot1_dist

summarise(boot1, mean = mean(price))
```

Notice that our bootstrap distribution has a similar shape to the original sample distribution. Though the shapes of the distributions are similar, they are not identical. You'll also notice that the original sample mean and the bootstrap sample mean differ. How might that happen? Remember that we are sampling with replacement from the original sample, so we don't end up with the same sample values again. We are trying to mimic drawing another sample from the population without actually having to do that.

Let's now take 1500 bootstrap samples from the original sample we drew from the population (`one_sample`)  using `rep_sample_n` and calculate the means for each of those replicates.

```{r 10-bootstrapping4, echo = TRUE, message = FALSE, warning = FALSE}
boot1500 <- one_sample %>%
    rep_sample_n(size = 40, replace = TRUE, reps = 1500)
head(boot1500)
tail(boot1500)
boot1500_means <- boot1500 %>% 
  group_by(replicate) %>% 
  summarize(mean = mean(price))
head(boot1500_means)
tail(boot1500_means)
```

Why are we doing this? As mentioned earlier, in reality, we typically only have one sample. So we can sample from that original sample with replacement (i.e., bootstrapping) many times to create many bootstrap samples. We can then calculate point estimates for each bootstrap sample and generate a bootstrap distribution of our point estimates. The bootstrap distribution suggests how we might expect our point estimate to behave if we took another sample.

```{r 10-bootstrapping5, echo = TRUE, message = FALSE, warning = FALSE, fig.cap = "Distribution of the bootstrap sample means"}
boot_est_dist <-  ggplot(boot1500_means, aes(x = mean)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Sample mean price per night ($)") 
```

Let's compare our bootstrap distribution with a sampling distribution. What do you notice? 
```{r 10-bootstrapping6, echo = F, message = FALSE, warning = FALSE, fig.cap = "Comparison of distribution of the bootstrap sample means and sampling distribution"}

samples <- rep_sample_n(airbnb, size = 40, reps = 1500)

sample_estimates <- samples %>% 
    group_by(replicate) %>% 
    summarise(sample_mean = mean(price))

sampling_dist <-  ggplot(sample_estimates, aes(x = sample_mean)) +
    geom_histogram(fill="#0072B2", color="#e9ecef") +
    xlab("Sample mean price per night ($)")

sampling_dist <- sampling_dist +
  annotate("text", x = max_x(sampling_dist), max_count(sampling_dist), hjust = 1, vjust =1,
           label = paste("mean = ", round(mean(sample_estimates$sample_mean), 1))) + 
  annotate("text", x = max_x(sampling_dist), max_count(sampling_dist), hjust = 1, vjust =3,
           label = paste("sd = ", round(sd(sample_estimates$sample_mean), 1))) + 
  geom_vline(xintercept = mean(sample_estimates$sample_mean), col = "red")

annotated_boot_est_dist <- boot_est_dist + 
  annotate("text", x = max_x(boot_est_dist), max_count(boot_est_dist), hjust = 1, vjust =1,
           label = paste("mean = ", round(mean(boot1500_means$mean), 1))) + 
    annotate("text", x = max_x(boot_est_dist), max_count(boot_est_dist), hjust = 1, vjust =3,
           label = paste("sd = ", round(sd(boot1500_means$mean), 1))) + 
  geom_vline(xintercept = mean(boot1500_means$mean), col = "red")

grid.arrange(sampling_dist + xlim(min_x(sampling_dist), max_x(sampling_dist)) + ggtitle("Sampling distribution"), 
             annotated_boot_est_dist + xlim(min_x(sampling_dist), max_x(boot_est_dist)) + ggtitle("Bootstrap distribution"),
             ncol = 2)
```
First, we see how the sampling distribution is centred at \$`r round(mean(airbnb$price),2)`, the population mean value. The sampling is random, and the estimates are centred at the population mean, as we learned in the previous section. However, the bootstrap distribution is centred at \$`r round(mean(boot1500_means$mean), 2)`, which is the original sample's mean price per night. Remember that we are resampling from the original sample over and over again, so we see that the bootstrap distribution is centred at the original sample's mean value. We also notice that the shape and spread of the two distributions are somewhat similar. 

```{r 10-bootstrapping7, echo = F, message = FALSE, warning = FALSE, fig.cap = "Summary of bootstrapping process"}
pop_dist <- population_distribution + ggtitle("Population") + xlab("Price") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())

sam_dist <- one_sample_dist + ggtitle("Sample")+ xlab("Price") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
set.seed(2)
boot2 <- one_sample %>%
    rep_sample_n(size = 40, replace = TRUE, reps = 1)

set.seed(3)
boot3 <- one_sample %>%
    rep_sample_n(size = 40, replace = TRUE, reps = 1)

boot1_dist <- boot1_dist + ggtitle("Samples with Replacement") + 
  theme(axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
        
boot2_dist <- ggplot(boot2, aes(price)) + 
    geom_histogram(fill="#0072B2", color="#e9ecef") + 
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())

boot3_dist <- ggplot(boot3, aes(price)) + 
    geom_histogram(fill="#0072B2", color="#e9ecef") + xlab("Price") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) 

bootstrap_dist <- boot_est_dist+ ggtitle("Bootstrap \nDistribution") + xlab("Sample means") + 
    theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(), 
        axis.title.y =element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) 

mygb = function(x,y) {
  grid.bezier(x=x, y=y, gp=gpar(fill="black"), 
              arrow=arrow(type="closed", length=unit(2,"mm")))}

grid.arrange(pop_dist, 
             sam_dist, 
             boot1_dist, 
             boot2_dist, 
             boot3_dist,
             bootstrap_dist,
  widths = c(1, 1, 1, 1, 1),
  layout_matrix = rbind(c(1, NA, 3, NA, 6),
                        c(1, 2, 4, NA, 6),
                        c(NA, NA, 5, NA, NA)
)) 
grid.text(paste("mean =", round(mean(boot1$price)), sep = " "), x = unit(0.7, "npc"), 
          y = unit(.8, "npc"),gp = gpar(fontsize=12))
grid.text(paste("mean =", round(mean(boot2$price)), sep = " "), x = unit(0.7, "npc"), 
          y = unit(.5, "npc"),gp = gpar(fontsize=12))
grid.text(paste("mean =", round(mean(boot3$price)), sep = " "), x = unit(0.7, "npc"), 
          y = unit(.2, "npc"),gp = gpar(fontsize=12))
# arrows: pop to sample 
mygb(x=c(0.15,0.3,0.3,0.3), y=c(0.8,0.8,0.65,0.65))

# arrows: sample to resamples
mygb(x=c(0.35,0.35,0.42,0.42), y=c(0.55,0.55,0.8,0.8))
mygb(x=c(0.35,0.35,0.42,0.42), y=c(0.5,0.5,0.5,0.5))
mygb(x=c(0.35,0.35,0.42,0.42), y=c(0.45,0.45,0.2,0.2))

# arrows: resamples to statistics
mygb(x=c(0.57,0.57,0.62,0.62), y=c(0.8,0.8,0.8,0.8))
mygb(x=c(0.57,0.57,0.62,0.62), y=c(0.5,0.5,0.5,0.5))
mygb(x=c(0.57,0.57,0.62,0.62), y=c(0.2,0.2,0.2,0.2))

# arrows: statistics to boot
mygb(x=c(0.77,0.77,0.83,0.83), y=c(0.8,0.8,0.7,0.7))
mygb(x=c(0.77,0.77,0.83,0.83), y=c(0.5,0.5,0.6,0.6))
mygb(x=c(0.77,0.77,0.83,0.83), y=c(0.2,0.2,0.4,0.4))

# dots 
grid.text(".", x = unit(0.45, "npc"), 
          y = unit(0.04, "npc"),gp = gpar(fontsize=15))
grid.text(".", x = unit(0.45, "npc"), 
          y = unit(0.06, "npc"),gp = gpar(fontsize=15))
grid.text(".", x = unit(0.45, "npc"), 
          y = unit(0.025, "npc"),gp = gpar(fontsize=15))

grid.text(".", x = unit(0.7, "npc"), 
          y = unit(0.14, "npc"),gp = gpar(fontsize=15))
grid.text(".", x = unit(0.7, "npc"), 
          y = unit(0.16, "npc"),gp = gpar(fontsize=15))
grid.text(".", x = unit(0.7, "npc"), 
          y = unit(0.18, "npc"),gp = gpar(fontsize=15))

```

### Using bootstrapping to calculate a plausible range  
Now that we have constructed our bootstrap distribution let's use it to create a confidence interval for the mean, a range of plausible values for the population mean. Confidence intervals can be set at different levels. Common levels are 90\%, 95\% and 99\%. There is a balance between your level of confidence and an interval's precision, so the confidence level you choose will depend on the application. Suppose we want to construct a 95\% confidence interval using the bootstrap distribution we found earlier.

To calculate a 95% confidence interval using bootstrapping: 

1. Arrange the observations in the bootstrap distribution in ascending order 
2. Find the value such that 2.5\% of observations fall below it (the 2.5\% percentile). Use that value as the lower bound of the interval 
3. Find the value such that 97.5\% of observations fall below it (the 97.5\% percentile). Use that value as the upper bound of the interval

To do this in R, we can use the `quantile()` function:

```{r 10-bootstrapping8, echo = T, message = FALSE, warning = FALSE}
bounds <- boot1500_means %>% 
    select(mean) %>% 
    pull() %>% 
    quantile(c(0.025, 0.975))
bounds
```


We're 95\% "confident" that the true population mean price per night of Airbnb listings in Vancouver is between \$`r round(bounds[1],2) ` and \$`r round(bounds[2],2)`. Suppose we repeated this process of sampling and constructing confidence intervals more times with more samples. We'd expect 95\% of intervals would contain the true population parameter. 

```{r 10-bootstrapping9, echo = F, message = FALSE, warning = FALSE, fig.cap = "Distribution of the bootstrap sample means with 95% confidence interval lower and upper bounds"}
boot_est_dist + 
  geom_vline(xintercept = bounds, col = "#E69F00", size = 2, linetype = 2) + 
  annotate("text", x = bounds[1], max_count(boot_est_dist), hjust = 0.5, vjust =2,
           label = paste("2.5th percentile =", round(bounds[1], 2))) + 
    annotate("text", x = bounds[2], max_count(boot_est_dist), hjust = 0.5, vjust =2,
           label = paste("97.5th percentile =", round(bounds[2], 2)))
```
Here we notice that our 95\% confidence interval does indeed contain the true population mean value, \$`r round(mean(airbnb$price),2)`\! However, in practice, we would not know whether our interval captured the true population parameter or not because we usually only have a single sample, not the entire population.

## Additional readings

For more about statistical inference and bootstrapping, refer to pages 187-190  
of [Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani, and Chapters 7 - 8 of [Modern Dive](https://moderndive.com/) Statistical Inference via Data Science by Chester Ismay and Albert Y. Kim
